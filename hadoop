$ sudo apt-get update

Step 2:Install Java and Set JAVA_HOME

    //This first thing to do is to setup the webupd8 ppa on your system. Run the following command and proceed.

$ sudo apt-add-repository ppa:webupd8team/java
$ sudo apt-get update

//After setting up the ppa repository, update the package cache as well.

//Install the Java 8 installer

$ sudo apt-get install install openjdk-7-jdk

   $java-version







Step 3: Add a dedicated Hadoop user

$ sudo addgroup hduser


$ sudo adduser --ingroup hadoop hduser

// Add hduser to sudo user group

   $ sudo adduser hduser sudo


Step 4:Install SSH and Create Certificates

$ sudo apt-get install ssh

$ su hduser

$ ssh-keygen -t rsa -P ""

// Set Environmental variables
$ cd ./ssh 
$ ls -l 
   

$ ssh-copy-id-i /home/hduser/.ssh/id-rsa.pub localhost
In the below screenshot the key already generated and copied
   

Step 5: Check if SSH works

$ ssh localhost

Step 6:Install Hadoop

$ wget https://archive.apache.org/dist/hadoop/core/hadoop-2.8.4/hadoop-2.8.4.tar.gz
 


/ Extract Hadoop-2.7.2
$ sudo tar xvzf hadoop-2.7.2.tar.gz

   

   

// Create a folder ‘hadoop’ in /usr/local
$ sudo mkdir –p /usr/local/hadoop

 

// Move the Hadoop folder to /usr/local/hadoop
$ sudo mv hadoop-2.8.4 /usr/local/hadoop 

 
/ Assigning read and write access to Hadoop folder
$ sudo chown –R hduser:hadoop /usr/local/hadoop

 

Step 7: Modify Hadoop config files

//Hadoop Environmental variable setting – The following files will be modified
~/.bashrc
/usr/local/hadoop/hadoop-2.8.4/etc/hadoop/hadoop-env.sh
/usr/local/hadoop/hadoop-2.8.4/etc/hadoop/core-site.xml
/usr/local/hadoop/hadoop-2.8.4/etc/hadoop/hdfs-site.xml
/usr/local/hadoop/hadoop-2.8.4/etc/hadoop/yarn-site.xml
/usr/local/hadoop/hadoop-2.8.4/etc/hadoop/mapred-site.xml.template
$ sudo nano ~/.bashrc



// Add the following lines at the end of the file
   export JAVA_HOME=/usr/lib/jvm/java-7-openjkd-amd-64
export HADOOP_HOME=/usr/local/hadoop/hadoop-2.8.4 export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export HADOOP_OPTS="-D.java.library.path=$HADOOP_HOME/lib" export PATH=$PATH:/usr/local/hadoop/hadoop-2.8.4/bin



// Configure Hadoop Files
$ cd /usr/local/hadoop/hadoop-2.8.4/etc/hadoop/
$ sudo nano hadoop-env.sh

 
// Add following line in hadoop-env.sh – Set JAVA variable in Hadoop
# The java implementation to use.
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd-64

 
// Edit hdfs-site.xml
$ sudo nano hdfs-site.xml
<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/usr/local/hadoop_tmp/hdfs/namenode</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/usr/local/hadoop_tmp/hdfs/datanode</value>
</property>
</configuration>

 

// Edit core-site.xml

$ sudo nano core-site.xml

// Add the following lines between <configuration> …… </configuration>
<configuration>
<property>
<name>fs.default.name</name>
<value>hdfs://localhost:9000</value>
</property>
</configuration>
 

// Edit yarn-site.xml

$ sudo nano yarn-site.xml

// Add the following lines between <configuration> …… </configuration>
<property>
<configuration>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.Shuffle-Handler</value>
</property>
</configuration>





















sudo nano mapred-site.xml
// Add the following lines between <configuration> …… </configuration>
<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
</configuration>
  

Step 8 – Format Hadoop File System

$ cd /usr/local/hadoop/hadoop-2.8.4

$  bin/hadoop namenode -format
 

Step 9 - Start Hadoop

$ cd /usr/local/hadoop/hadoop-2.7.2/sbin

// Starting dfs services

$ start-dfs.sh

  
// Starting mapreduce services

$ start-yarn.sh



$ jps


